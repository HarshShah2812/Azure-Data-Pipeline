# End-to-end Data Pipeline

> This project is about setting up an end-to-end data pipeline using Azure (Data Lake Gen2, Data Factory, Databricks), Apache Spark, and dbt (Data Build Tool)

## Overview
The aim of the project is to illustrate the process of data ingestion into a data lake, followed by data integration using Azure Data Factory, and then data transformation using Databricks and dbt.

## Project Architecture

![architecture](https://github.com/airscholar/modern-data-eng-dbt-databricks-azure/blob/main/System%20Architecture.jpeg)