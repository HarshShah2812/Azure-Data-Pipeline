# End-to-end Data Pipeline

> This project is about setting up an end-to-end data pipeline using Azure (Data Lake Gen2, Data Factory, Databricks), Apache Spark, and dbt (Data Build Tool)

## Overview
The aim of the project is to illustrate the process of data ingestion into a data lake, followed by data integration using Azure Data Factory, and then data transformation using Databricks and dbt.

## Project Architecture

![architecture](/Users/harshshah/Documents/DE_projects/de-pipeline-dbt-databricks-azure/medallion_dbt_spark/System Architecture.jpeg)